---
title: 'HTTP'
date: '2022-10-15'
keywords: ['Computer Network']
---

## HTTP 特征

- **简单快速**：客户端向服务端发起请求的时候，只需要说明请求方法和请求路径
- **灵活**：HTTP 允许传输任意类型的数据，只需要使用 Content-Type 标明
- **无状态**：HTTP 没有记忆能力

## HTTP 报文

HTTP 报文用于在客户端和服务端之间传送数据。HTTP 由请求（Request）和响应（Response）组成。

HTTP 报文由三大部分组成：
- **起始行**：描述请求或响应的基本信息
- **header**：header 不能为空
- **body**：实际传输的数据，不一定是纯文本，也可以是视频、图片等。body 可以为空

通过 `curl -v https://www.baidu.com` 可以获得完整的请求报文、响应报文以及响应体。报文格式如下，报文每行由 \r\n 换行：

```bash
# 请求报文

# 首行由 Method Path Version 构成
# 每一行结尾是 \r\n
GET / HTTP/1.1
# 以下是请求头，Host 是请求的域名
Host: www.baidu.com
User-Agent: curl/7.79.1
Accept: */*

# 响应报文
# 相隔两个 \r\n，将会收到响应报文

# 首行由 Version StatusCode 状态描述符组成
HTTP/1.1 200 OK
# 以下是响应头
Accept-Ranges: bytes
Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform
Connection: keep-alive
Content-Length: 2443
Content-Type: text/html
Date: Wed, 31 Aug 2022 09:23:42 GMT
Etag: "58860402-98b"
Last-Modified: Mon, 23 Jan 2017 13:24:18 GMT
Pragma: no-cache
Server: bfe/1.0.8.18
Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/

# 响应体
# 相隔两个 \r\n，将会收到响应体
<!DOCTYPE html>
...
```

为什么使用 `\r\n` 作为换行呢？其实现在除了 Windows 把 `\r\n` 作为换行符，其他系统都是把 `\n` 作为换行符的。这里有一个有意思的背景：由于早期各个系统之间的换行符（LF、CR、CRLF、LFCR...）乱成一团，为了保证互联网的适用性，互联网之父们制定了一个规则：所有在互联网上传输的 ASCII 文本的换行符都必须遵守使用 CRLF（即 `\r\n`）作为换行符的规定，再由不同的操作系统将 CRLF 翻译为自己适用的换行符，这样让所有的操作系统平摊痛苦、避免吵架。

## GET 和 POST 请求的区别

- 语义不同
- GET 参数放在 URL 后面，POST 放在报文实体中
- GET 安全幂等、POST 不安全不幂等（对于服务器来说），安全指是否会修改服务器上的资源、幂等指多次请求结果是否相同
- GET 提交的数据大小有限制，POST 无限制。注意：GET 本身并没有对数据长度进行限制，真正限制的是浏览器。对于不同的浏览器，GET 限制的长度可能不同
- GET 只支持  ASCII 字符，POST 无限制
- GET 一般会被缓存，POST 一般不会被缓存

## HTTP 如何保存状态

前面说到，HTTP 是无状态协议，那如果我们需要保存登录态，可以怎样做呢？

1. **基于 Session 实现会话保持**：客户端第一次向服务端发送 HTTP 请求后，服务器创建 Session 并将客户端身份信息以键值对形式保存下来，然后分配一个 SessionId 给客户端。SessionId 一般会保存在客户端的 Cookie 中，之后每次浏览器的 HTTP 请求都会带上 Cookie 到服务器，服务器根据 Cookie 中的 SessionId 就可以知道用户是谁。优点：安全性高，因为状态保存在服务器端；缺点：因为大型网站用的是分布式服务器，多次 HTTP 请求可能落到不同的服务器上，这样基于 Session 的方法就不能实现会话保持了。当然我们可以把 Session 存储在 Redis 中，这样服务器就都可以访问到之前的状态信息了
2. **基于 Set-Cookie 实现**：服务器响应的时候在 HTTP 响应头设置 Set-Cookie 字段，用来存储客户端状态信息。客户端设置 Cookie 后，每次浏览器发送 HTTP 请求会带上 Cookie。这种方式相当于完全把状态信息存储在浏览器 Cookie 中。优点：服务端存储压力减小；缺点：不够安全，而且每次 Cookie 需要携带很多内容，占用更多带宽

如果 Cookie 禁用怎么办？我们可以重写 URL，比如 js 有函数 `encodeURL()`

## 状态码

| 分类 | 描述 |
| ---- | ---- |
| 1xx | 请求正在处理 |
| 2xx | 请求成功处理 |
| 3xx | 重定向 |
| 4xx | 客户端错误 |
| 5xx | 服务端错误 |

## 常见状态码

| 状态码 | 英文描述 | 详细说明 |
| ---- | ---- | ---- |
| 100 | Continue | 服务器收到了请求的一部分，并且希望客户端继续发送其余部分
| 101 | Switching Protocols | 切换协议，服务端根据客户端请求的头信息切换协议
| 200 | OK | 请求成功处理
| 201 | Created | 请求成功，并且创建了新的资源
| 202 | Accepted | 请求成功，但是还没有处理完成
| 204 | No Content | 请求成功，服务器处理了部分请求
| 301 | Moved Permanently | 永久重定向。请求的资源分配了新的 URL，**之后**应该使用更改的 URL
| 302 | Found | 临时重定向。请求的资源被分配了新的 URL，希望**本次**访问使用新的 URL
| 400 | Bad Request | 请求报文存在语法错误或者请求参数有误
| 401 | Unauthorized | 用户未授权或权限不足
| 403 | Forbidden | 服务器拒绝本次请求
| 408 | Request Time-out | 服务器等待客户端发送的请求时间过长，超时了
| 500 | Internal Server Error | 服务器内部错误
| 502	| Bad Gateway	| 服务器作为网关或代理，从远程服务器接收到了无效的响应
| 503	| Service Unavailable	| 服务器超载或正在停机维护

## 301 和 302 的区别

### 定义 & 缓存

- **301**：永久重定向。请求的资源已被永久的移动到新的 URI，旧的地址已经被永久的删除了。返回信息会包括新的 URI，浏览器会自动定向到新的 URI，今后新的请求都应使用新的 URI 代替。默认情况下这个响应是可缓存的
- **302**：临时重定向。与 301 类似，客户端拿到服务端的响应消息后会跳转到一个新的 URL 地址。但资源只是临时被移动，旧的地址还在，客户端应继续使用原有 URI。302 的请求默认情况下是不缓存的，除非设置了 Cache-Control 或者 Expires

### 应用场景
- **301**：一般情况下用户输入的地址都不带有协议。比如 `www.baidu.com`。在这种情况下，浏览器会假设你想要使用 HTTP 协议，然后发送一个 HTTP 请求到 `www.baidu.com`，然后服务端会返回 301 状态码将请求重定向到 HTTPS 站点
- **302**：302 常用于用户登录的场景，比如说某个用户登录之前无法查看一些内容，会先跳转到登录界面，然后再回到原来的页面

### 搜索引擎
- **301**：旧地址的资源不可访问了，重定向到新的网址，且将网址保存为新的网址
- **302**：旧地址的资源依然可访问，只是这次抓取新网站的内容，网址依然保存原网址

## HTTP/1.0

### 特性

- 引入了请求头和请求体，增加了状态码，支持多种文档类型
- 使用短连接，每次发送数据都要经过三次握手和四次挥手，效率低
- header 中只使用 If-Modified-Since 和 Expires 作为缓存

### 缺点

- 不支持断点续传
- 每个 IP 只能有一个域名
- 只有前面的请求返回才能进行下一次请求，效率很低
- 需要在响应头设置 Content-Length，然后浏览器再根据设置的数据大小来接收数据，对于动态生成的数据无能为力
- 存在带宽浪费现象，有时候客户端只是需要资源的一部分，服务端却全部都传了过来

## HTTP/1.1

### 特性

- 缓存处理：HTTP/1.0 主要使用 If-Modified-Since，HTTP/1.1 增加了更多的请求头，如 ETag、If-Unmodified-Since、If-Match、If-None-Match
- Cookie：HTTP/1.1 引入了 Cookie
- 对动态生成的内容提供了完美的支持，通过 Transfer-Encoding: chunked 解决了这个问题。服务器会将数据分割成若干个任意大小的数据块，每个数据块发送时都会附上数据块的长度，最后使用一个零长度的块作为发送数据完成的标志
- 支持断点续传
- 节约带宽：客户端请求资源的时候，HTTP/1.0 默认将该资源相关的整个对象都传送给请求方，但很多时候可能客户端并不需要对象的所有信息，而在 HTTP/1.1 的请求头中引入了 range，它允许只请求部分的资源
- Host 请求头：HTTP/1.0 中每台服务器只能绑定唯一的 IP 地址，而随着虚拟主机出现，一台物理服务器上可能存在多台虚拟主机，并且共享同一个 IP。为了支持虚拟主机，HTTP/1.1 添加了 Host 请求头，同时也支持一个 IP 对应多个域名
- 持久连接：默认开启持久连接，如果要兼容旧版本，需要加上 Connection: keep-alive
- Pipeline 管道：客户端传送过程不需要等待响应才能发起下一次请求

### 缺点

- 同时开启多条 TCP 连接时，连接之间会互相竞争带宽
- 队头阻塞：管道化要求服务端必须按照请求发送的顺序返回响应，如果一个响应返回延迟了，那么其后续的响应都会被延迟，直到队头的响应送达。HTTP/1.1 的队头阻塞问题是因为自身协议设计导致的
- 请求头重复携带
- 服务端永远处于被动

### 为什么 HTTP/1.1 不能实现多路复用？

HTTP/1.1 不是二进制传输，而是通过文本进行传输。由于没有流的概念，在使用并行传输（多路复用）传递数据时，接收端在接收到响应后，并不能区分多个响应分别对应的请求，所以无法将多个响应的结果重新进行组装，也就实现不了多路复用。

### HTTP/1.1 可以如何优化？

- 尽量避免发送 HTTP 请求：使用缓存技术
- 在必须发送 HTTP 请求的时候，考虑如何减少请求的次数
  - 合并请求：可以将多个小文件的请求合并为一个大的请求，虽然传输的总资源是一定的，但是减少了请求的次数，这就意味着减少了重复发送 HTTP 头部
  - 延迟发送请求：比如图片懒加载
- 减少服务器 HTTP 响应的数据大小

## HTTP/2.0

### 特性

- 完全的二进制协议。头和体都是二进制，而 HTTP/1.1 的头必须是 ASCII 编码
- 多路复用。在一个连接中，客户端和服务器都可以同时发送多个请求或回应，不需要按顺序发送
- 数据流概念。HTTP/2.0 的数据包是不按顺序发送的，同一个连接中的数据包可能来源于不同的请求，所以需要对数据包做标记，指明属于哪个请求。为了防止两端的 ID 冲突，客户端发起的流具有奇数的 ID，服务端发起的流具有偶数的 ID
- 头部压缩。因为 HTTP 无状态，每次请求都必须带上所有的信息，所以很多的请求字段都是重复的，比如 User-Agent。一模一样的内容每次请求都要携带会浪费带宽，影响速度。通过 gzip 或者 compress 压缩头后再发送。另一方面，客户端和服务端都维护一张头信息表，部分字段会存储到表中，生成一个索引，以后相同的就只发送索引，不发生字段，这也叫 HPACK 算法
- 允许服务器主动推送。HTTP/2.0 允许服务器未经请求，主动向客户端推送一些必要资源

### 缺点

TCP 数据包是有序传输的，如果中间一个数据包丢失，会等待该数据包重传，造成后面数据包的阻塞。队头阻塞主要是 TCP 协议的可靠性机制引入的。TCP 使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理。
因为 HTTP/2.0 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。由于多个数据流使用同一个 TCP 连接，遵守同一个流量状态控制和拥塞控制。一旦发生丢包的情况，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须要去等待这个丢了的包被重传回来。所以当丢包率高的时候，HTTP/2.0 的表现甚至不如 HTTP/1.1。HTTP/2.0 出现的这个问题是由于其使用 TCP 协议的问题，与它本身的实现其实并没有多大关系。

## HTTP/3.0

### 特性

- Quick UDP Internet Connection
- 基于 UDP 实现了类似 TCP 的流量控制、可靠传输机制
- 集成了 TLS
- HTTPS 要建立连接的话，要花费 6 次交互，先是要建立三次握手，然后是 TLS 的三次握手。QUIC 直接把之前的 TCP 的三次握手和 TLS 的三次握手合并为了一共 3 次，减少了交互的次数
- 头部压缩算法使用了 QPACK
- 使用了 HTTP 2 的多路复用，再加上使用了 UDP，真正解决了队头阻塞问题
- 快速握手，快速启动。因为底层基于 UDP

### 缺点

- 服务端和客户端对 HTTP 3 的支持还不完善
- 在部署上存在较大难度

## HTTPS

### HTTP 存在的问题

- 明文传输，具有被窃听的风险，通过抓包工具就可以获取 HTTP 传输过程中的数据
- 传输内容可能被篡改，通过抓包工具可以获取 HTTP 传输的内容进行修改之后，再发送出去
- 存在被冒充的风险，因为冒充者可以收到发送方信息，也就可以冒充发送方给接收方发送信息

### HTTPS 如何解决 HTTP 存在的问题

- **信息加密**：HTTPS 使用混合加密的方式，解决了窃听风险。对称加密的双方只有一个密钥，加解密用的是同一个密钥，速度较快，但是密钥必须要保密；非对称加密有公钥和私钥，公钥公开，私钥自己保存，公钥加密的数据只能用私钥解密，私钥加密的数据只能用公钥解密。但是非对称加密的加解密速度较慢。所以 HTTPS 选择在通讯建立的时候使用非对称加密，正常沟通的时候使用对称加密，同时确保了安全性和性能。
- **校验机制**：为了保证传输内容不被篡改，客户端会先根据传输内容计算出一个 hash 值，然后把这个 hash 值和内容一起传输给服务端。服务端收到请求后，也会根据内容计算出一个 hash 值，然后跟对方传过来的 hash 进行一个比对，如果两个 hash 值相同，则说明内容没有被篡改。
- **数字证书**：如何确保客户端收到的公钥是服务端发送的，而不是中间人发送的呢？利用权威机构发布的 CA（数字证书认证机构）可以证明服务器的身份，只要证书可信那么公钥就可信。

### 混合加密的意义

- **公钥加密，私钥解密**。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
- **私钥加密，公钥解密**。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。
- 一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的，所以 HTTPS 中用的就是上面所说的**私钥加密，公钥解密**的方式

### TLS 握手

1. **ClientHello**：首先客户端向服务端发起加密通信请求。请求包含了 SSL/TLS 的协议版本、客户端生成的一个随机数 client_random（用于后续生成会话密钥）、客户端支持的加密算法（比如 RSA 加密算法）
2. **ServerHello**：服务端收到客户端的请求后，返回给客户端一个请求，内容包含确认的 SSL/TLS 版本以及加密算法、服务端生成的随机数 server_random（用于后续生成会话密钥）、服务器的数字证书
3. **客户端响应**：客户端收到服务器的响应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器公钥的正确性。确认服务器的公钥没问题之后，客户端生成一串随机字符串 premaster_secret，使用服务器的公钥加密它
4. **服务端响应**：服务端使用私钥解密上面的随机字符串 premaster_secret
5. **生成对称密钥**：此时服务端、客户端均拥有了生成密钥的三个要素 client_random、server_random、premaster_secret，可以使用之前协商的加密算法生成对称密钥
6. **客户端就绪**：客户端发送经过对称密钥加密过的 finished 信号
7. **服务端就绪**：服务端发送经过对称密钥加密过的 finished 信号
8. **握手完成**：接下来的会话都通过对称密钥加密

### RSA 加密算法

- 公钥：指纹 = 明文^E % N
- 私钥：指纹 = 密文^D % N 

![RSA-1](rsa-1.jpg)

![RSA-2](rsa-2.jpg)

### 数字证书和 CA

**数字证书通常包括**：

- 公钥
- 持有者信息
- CA 的信息
- 证书有效期
- CA 对文件的数字签名以及使用的算法

CA 就是网络世界中的公安局，具有极高的可信度，所以由它来给各个公钥签名，信任的一方签发的证书，必定也是可信任的。之所以要签名，是因为签名可以避免中间人在获取证书时对证书内容进行篡改。

**数字证书的签发和验证流程**：

- 签发：首先把持有者的公钥、持有者信息、证书有效期等信息打包成一个包，再对这些信息进行 hash 计算，得到一个 hash 值。然后使用自己的私钥对该 hash 进行加密，生成数字签名，最后把数字签名加入到证书中。
- 验证：客户端会使用同样的 hash 算法获取该证书的 hash 值 H1，然后使用浏览器和操作系统中集成的 CA 公钥来解密数字证书的内容来得到一个 H2，将二者进行比较。如果相同则证明该证书是可信的，如果不相同，则证明是不可信的。

